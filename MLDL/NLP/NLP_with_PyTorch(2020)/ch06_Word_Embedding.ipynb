{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch06_Word_Embedding.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python37764bitb5d3c5cb81604174903eb15794afea90","display_name":"Python 3.7.7 64-bit"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ds5GwezTvBun","colab_type":"text"},"source":["# Ch06. Word Embedding\n","\n","- frequency, 유사도 등 적용하더라도, 여전히 sparse vector - 차원의 저주 문제\n","- 가능한 낮은 차원으로 표현, 쉽게 모델링, 학습할 수 있도록, dense vector로 표현할 필요성\n","\n","## PCA; principal component analysis, 주성분 분석\n","\n","- 대표적인 차원 축소 방법\n","- SVD ; singular value decomposition, 특잇값 분해\n","- 차원 축소 과정에서 정보 손실 불가피\n","- 특히 데이터가 비선형적으로 구성될수록 더욱 어려워짐\n","\n","## Manifold Hypothesis\n","\n","![https://gblobscdn.gitbook.com/assets%2F-LFzjkZt6ljMBd4YGVCn%2F-LX4NCwvtTXyg_vzXhF0%2F-LX4NGyqIODsdqDXE9kz%2F06-02-05.png?alt=media](https://gblobscdn.gitbook.com/assets%2F-LFzjkZt6ljMBd4YGVCn%2F-LX4NCwvtTXyg_vzXhF0%2F-LX4NGyqIODsdqDXE9kz%2F06-02-05.png?alt=media)\n","\n","- 높은 차원에 존재하는 데이터들의 경우, 해당 데이터들을 아우르는 낮은 차원의 manifold다양체가 존재한다는 가정\n","- 고차원상에서 가까운 거리에 있는 데이터 포인트들이 저차원 공간에서 거리가 멀어질 수 있음\n","- 저차원 공간상 가까운 점끼리는 실제로 비슷한 특징 가짐\n","- 대부분의 딥러닝 차원 축소 과정은 고차원상의 manifold를 찾는 과정; 비선형적 방식으로 차원 축소를 하기 때문, 딥러닝이 성공적으로 동작하는 이유일 것\n","\n","## AutoEncoder\n","\n","- Original High Dimension -> encoder -> latent low dimension -> decoder -> high dimension\n","- 저차원으로 축소된 bottle-neck 차원에서 복원에 필요한 정보만 남기고 필요없는 정보 제거; 복원 오차\n","\n","## 주의사항\n","\n","- word2vec을 통해 얻은 pre-training embedding vector는 NLP 최적의 embedding vector가 아니다; classification / translation 등 문제 종류에 따라, 목적 함수는 word2vec과 다른 형태로 존재\n","\n","### word2vec 없이 nn 훈련하기\n","\n","- embedding layer; one-hot vector 대신 단어 index 값만 lookup으로 return\n","- PyTorch 등 대부분의 DL framework에서 제공\n","\n","### word2vec을 사용해야 하는 경우\n","\n","- 준비된 corpus 양이 너무 적은 경우\n","- 정석대로 baseline model 만든 후, 성능 끌어올리기 위한 방법 시도하는 경우\n","- transfer learning 전이학습에서 고도화된 언어 모델 사용하는 경우\n","\n","## word2vec\n","\n","embedding 방식 ; 두 방법 모두, 함께 등장하는 단어 비슷할수록 비슷한 벡터 값 가진다는 가정, 특정 단어 기준으로 윈도우 내 주변 단어들 사용해 embedding 학습, 윈도우 내 위치는 고려하지 않지만 위치 정보는 포함\n","\n","### CBOW\n","\n","- 주변 단어들의 one-hot-encoding vector 입력 받아 단어 예측\n","\n","### Skip-gram\n","\n","- 해당 단어의 one-hot-encoding vector 입력 받아 주변 단어 예측하는 네트워크 구성\n","- 보통 CBOW 보다 성능 더 뛰어난 것으로 알려져 더 널리 쓰임\n","\n","## GloVe\n","\n","- Global Vectors for word representation\n","- 대상 단어에 대해 corpus에 함께 나타난 단어별 출현 빈도 예측\n","- Skip-gram 네트워크와 거의 유사, 다만 classification 문제가 아닌 출현 빈도를 근사하는 regression 문제가 되었기 때문에 MSE 평균제곱오차 사용\n","- 단어 x 자체의 출현 빈도 또는 사전확률 prior probability에 따라 MSE 손실함수 값이 매우 달라짐, 따라서 단어 빈도에 따라 손실함수에 가중치 부여\n","- GloVe 논문에서는 thres = 100, alpha = 3/4 일 때 가장 좋은 결과 나온다고 언급\n","\n","\n","## word2vec Example.\n","\n","- 대표적인 embedding open library : Gensim, FastText\n","\n","### Gensim\n","\n","- 공개 연혁이 상대적으로 오래되어, 학습 속도가 더 느림\n","\n","### FastText\n","\n","- Facebook에서 공개, 빠른 속도가 장점\n","- https://github.com/facebookresearch/fastText\n","- 단어 embedding vector, 텍스트 분류 훈련 기능 등\n","\n"]},{"cell_type":"code","metadata":{"id":"RMGWbJP8lXCo","colab_type":"code","outputId":"32162a2e-cbd1-44a5-efd2-382142b88bff","executionInfo":{"status":"ok","timestamp":1591144190784,"user_tz":-540,"elapsed":1198,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","\n","os.getcwd()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/workspaces/Java_Spring/Python/MLDL/MLDL_Study/lecture_notes/NLP_with_PyTorch(2020)'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"2JmNMnQbvQyd","colab_type":"code","outputId":"5e4b1ab9-7365-4438-a68f-05a4f6746bbc","executionInfo":{"status":"ok","timestamp":1591144134278,"user_tz":-540,"elapsed":4194,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["!git clone https://github.com/facebookresearch/fastText.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'fastText'...\n","remote: Enumerating objects: 14, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 3840 (delta 1), reused 7 (delta 1), pack-reused 3826\u001b[K\n","Receiving objects: 100% (3840/3840), 8.21 MiB | 1.69 MiB/s, done.\n","Resolving deltas: 100% (2410/2410), done.\n","Checking out files:  50% (263/526)Checking out files:  51% (269/526)Checking out files:  52% (274/526)Checking out files:  53% (279/526)Checking out files:  53% (284/526)Checking out files:  54% (285/526)Checking out files:  55% (290/526)Checking out files:  56% (295/526)Checking out files:  57% (300/526)Checking out files:  57% (301/526)Checking out files:  58% (306/526)Checking out files:  59% (311/526)Checking out files:  60% (316/526)Checking out files:  61% (321/526)Checking out files:  62% (327/526)Checking out files:  63% (332/526)Checking out files:  64% (337/526)Checking out files:  64% (338/526)Checking out files:  65% (342/526)Checking out files:  66% (348/526)Checking out files:  66% (351/526)Checking out files:  67% (353/526)Checking out files:  68% (358/526)Checking out files:  69% (363/526)Checking out files:  70% (369/526)Checking out files:  71% (374/526)Checking out files:  72% (379/526)Checking out files:  72% (383/526)Checking out files:  73% (384/526)Checking out files:  74% (390/526)Checking out files:  75% (395/526)Checking out files:  76% (400/526)Checking out files:  77% (406/526)Checking out files:  78% (411/526)Checking out files:  79% (416/526)Checking out files:  80% (421/526)Checking out files:  81% (427/526)Checking out files:  81% (429/526)Checking out files:  82% (432/526)Checking out files:  83% (437/526)Checking out files:  84% (442/526)Checking out files:  85% (448/526)Checking out files:  86% (453/526)Checking out files:  87% (458/526)Checking out files:  88% (463/526)Checking out files:  89% (469/526)Checking out files:  90% (474/526)Checking out files:  90% (477/526)Checking out files:  91% (479/526)Checking out files:  92% (484/526)Checking out files:  93% (490/526)Checking out files:  93% (493/526)Checking out files:  94% (495/526)Checking out files:  95% (500/526)Checking out files:  96% (505/526)Checking out files:  97% (511/526)Checking out files:  98% (516/526)Checking out files:  99% (521/526)Checking out files: 100% (526/526)Checking out files: 100% (526/526), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ad-AXU4uSfsH","colab_type":"text"},"source":["***linux / mac에서 설치시 g++(C++ compiler) 필요***"]},{"cell_type":"code","metadata":{"id":"UzaltvtPvQ3R","colab_type":"code","outputId":"2ec08eac-86bb-42f5-a0f9-6b85f0f77ae1","executionInfo":{"status":"ok","timestamp":1591144305247,"user_tz":-540,"elapsed":44449,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["!pip install ./fastText/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Processing ./fastText\n","Requirement already satisfied: pybind11>=2.2 in /opt/conda/envs/py37/lib/python3.7/site-packages (from fasttext==0.9.2) (2.5.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/envs/py37/lib/python3.7/site-packages (from fasttext==0.9.2) (46.2.0.post20200511)\n","Requirement already satisfied: numpy in /opt/conda/envs/py37/lib/python3.7/site-packages (from fasttext==0.9.2) (1.18.1)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=4441067 sha256=4161f3645d04bad4bdf3cdb02675c5b031dae43a90e9aaab1173d310176ed47c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cs0k5eq9/wheels/fe/36/ec/e22824ef645889bcbaa50970d5ca2eab23d31d9dab6f273fd7\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y3wvMwDEvQ8O","colab_type":"code","outputId":"8cf0fd06-337e-4641-ed38-4e0b81b330b1","executionInfo":{"status":"ok","timestamp":1591144318047,"user_tz":-540,"elapsed":640,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}},"colab":{"base_uri":"https://localhost:8080/","height":434}},"source":["import fasttext\n","\n","dir(fasttext)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['BOW',\n"," 'EOS',\n"," 'EOW',\n"," 'FastText',\n"," '__builtins__',\n"," '__cached__',\n"," '__doc__',\n"," '__file__',\n"," '__loader__',\n"," '__name__',\n"," '__package__',\n"," '__path__',\n"," '__spec__',\n"," 'absolute_import',\n"," 'cbow',\n"," 'division',\n"," 'load_model',\n"," 'print_function',\n"," 'skipgram',\n"," 'supervised',\n"," 'tokenize',\n"," 'train_supervised',\n"," 'train_unsupervised',\n"," 'unicode_literals']"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"p0QW6w4mvRH8","colab_type":"code","colab":{},"outputId":"42de62e4-b8fe-4f46-a4f4-55873b489971"},"source":["from fasttext import skipgram\n","\n","dir(skipgram)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__annotations__',\n"," '__call__',\n"," '__class__',\n"," '__closure__',\n"," '__code__',\n"," '__defaults__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__get__',\n"," '__getattribute__',\n"," '__globals__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__kwdefaults__',\n"," '__le__',\n"," '__lt__',\n"," '__module__',\n"," '__name__',\n"," '__ne__',\n"," '__new__',\n"," '__qualname__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"PGjMAlOTvRKi","colab_type":"code","colab":{},"outputId":"47e287a5-e8ba-4ddb-8984-f3173c134529"},"source":["skipgram?"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDocstring:\u001b[0m <no docstring>\n","\u001b[0;31mFile:\u001b[0m      /opt/conda/envs/py37/lib/python3.7/site-packages/fasttext/FastText.py\n","\u001b[0;31mType:\u001b[0m      function\n"]}]},{"cell_type":"markdown","metadata":{"id":"zLNQE6P-vROJ","colab_type":"text"},"source":["## Visualization\n","\n","- PyTorch에는 자체 시각화 툴 없음\n","- Tensorflow의 Tensor Board 활용"]}]}