{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch05_Similarity_Ambiguity.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPlz1wsnr77GAVoxM0SSfDn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Dg0vfVaMDigL","colab_type":"text"},"source":["# ch05. 유사성과 모호성\n","\n","- 중의성 문제; 외부 형태 - 내부 의미\n","- 동형어 homonym\n","- 다의어 polysemy\n","- 단어 중의성 해소 WSD; word-sense disambiguation\n","- 동의어 synonym - 동의어 집합 synset\n","- 상위어 hypernym - 하위어 hyponym\n","\n","## One-hot encoding\n","\n","- 보통 3만~10만 차원 ; sparse vector\n","- 벡터 간 연산에서 결과값이 0이 되는, 직교orthogonal하는 경우가 많아짐\n","- 차원의 저주\n","\n","## Thesaurus\n","\n","노드 간 거리를 통해 단어간 유사도 측정\n","\n","- WordNet (Eng) : 단어에 대한 상위어-하위어 정보 구축, Directed Acyclic Graph 유향 비순환 그래프; 트리 구조 아님, NLTK에 포함\n","- KorLex : http://korlex.pusan.ac.kr/\n","- KWN : http://wordnet.kaist.ac.kr/\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"AVHHgSUGecxX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"34070e42-9304-4dca-ba7c-fbe9611490d3","executionInfo":{"status":"ok","timestamp":1591058493335,"user_tz":-540,"elapsed":4121,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["!pip install nltk"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhTFzuKUfEEj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"a2133ada-8852-472b-a4a5-214975565003","executionInfo":{"status":"ok","timestamp":1591058655820,"user_tz":-540,"elapsed":1100,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["import nltk\n","nltk.download('wordnet')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"X25UHUcPeYJV","colab_type":"code","colab":{}},"source":["from nltk.corpus import wordnet as wn\n","\n","def hypernyms(word) : \n","    current_node = wn.synsets(word)[0]\n","    yield current_node\n","\n","    while True :\n","        try:\n","            current_node = current_node.hypernyms()[0]\n","            yield current_node\n","        except IndexError :\n","            break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXGeifjnexFU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e36af515-a388-4167-b6ef-d8e76b6a7f93","executionInfo":{"status":"ok","timestamp":1591058727884,"user_tz":-540,"elapsed":608,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["hypernyms('policeman')"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object hypernyms at 0x7fd94726bd58>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Q6mFiJdFe8Dt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"44de83cf-6bc9-43da-d738-c41b6442c81a","executionInfo":{"status":"ok","timestamp":1591058742496,"user_tz":-540,"elapsed":545,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["type(hypernyms('policeman'))"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["generator"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"sys4eBnUfbpk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"28bab70c-b2b0-43e3-f701-b27607dd019c","executionInfo":{"status":"ok","timestamp":1591058752488,"user_tz":-540,"elapsed":694,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["list(hypernyms('policeman'))"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Synset('policeman.n.01'),\n"," Synset('lawman.n.01'),\n"," Synset('defender.n.01'),\n"," Synset('preserver.n.03'),\n"," Synset('person.n.01'),\n"," Synset('causal_agent.n.01'),\n"," Synset('physical_entity.n.01'),\n"," Synset('entity.n.01')]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"-YyAmbZ2feDV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9772eb25-9d3d-40cf-9186-c8c8942aa551","executionInfo":{"status":"ok","timestamp":1591058918534,"user_tz":-540,"elapsed":638,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["list(hypernyms('policeman'))[0]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Synset('policeman.n.01')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"R8xNi8Z8gJ0c","colab_type":"text"},"source":["## Feature Vector\n","\n","- 의미가 비슷하다면, 쓰임새가 비슷할 것\n","- 쓰임새가 비슷하면, 비슷한 문장 안에서 비슷한 역할로 사용될 것\n","- 함께 나타나는 단어들이 유사할 것\n","\n","## TF-IDF\n","\n","- TF ; term frequency, 단어의 문서 내 출현 횟수\n","- IDF ; inverse document frequency, 단어가 출현한 문서 수의 역수\n","- 특정 문서에만 잘나타나는 단어 - 중요한 역할 차지하는 단어 확인\n","- 'the'와 같이 일반적으로 나타나는 단어 제거\n","\n"]},{"cell_type":"code","metadata":{"id":"-NlWoOASguB2","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","def get_term_frequency (document, word_dict = None) :\n","    if word_dict is None : \n","        word_dict = {}\n","    words = document.split()\n","\n","    for w in words : \n","        word_dict[w] = 1 + (0 if word_dict.get(w) is None else word_dict[w])\n","    \n","    return pd.Series(word_dict).sort_values(ascending=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"etABPM0BguEU","colab_type":"code","colab":{}},"source":["def get_document_frequency(documents) :\n","    dicts = []\n","    vocab = set([])\n","    df = {}\n","\n","    for d in documents :\n","        tf = get_term_frequency(d)\n","        dicts += [tf]\n","        vocab = vocab | set(tf.keys())\n","\n","    for v in list(vocab) :\n","        df[v] = 0\n","        for dict_d in dicts :\n","            if dict_d.get(v) is not None :\n","                df[v] += 1\n","\n","    return pd.Series(df).sort_values(ascending = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkPXqM2OpolA","colab_type":"text"},"source":["***TF-IDF 구하는 최종 함수***"]},{"cell_type":"code","metadata":{"id":"O4kNEWT5guHt","colab_type":"code","colab":{}},"source":["def get_tfidf(docs) :\n","    vocab = {}\n","    tfs = []\n","    for d in docs : \n","        vocab = get_term_frequency(d, vocab)\n","        tfs += [get_term_frequency(d)]\n","    df = get_document_frequency(docs)\n","\n","    from operator import itemgetter\n","    import numpy as np\n","\n","    stats = []\n","    for word, freq in vocab.items() :\n","        tfidfs = []\n","        for idx in range(len(docs)) :\n","            if tfs[idx].get(word) is not None :\n","                tfidfs += [tfs[idx][word] * np.log(len(docs) / df[word]) ]\n","            else : tfidfs += [0]\n","        stats.append((word, freq, *tfidfs, max(tfidfs)))\n","    return pd.DataFrame(stats, columns = ('word', 'frequency', 'doc1', 'doc2', 'doc3', 'max')).sort_values('max', ascending = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxE7_YYOguJg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":709},"outputId":"ada0924c-4f93-461f-8ee5-74cb29316f99","executionInfo":{"status":"ok","timestamp":1591061956720,"user_tz":-540,"elapsed":1237,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["doc1 = '''\n","지능 지수 라는 말 들 어 보 셨 을 겁니다 . 여러분 의 지성 을 일컫 는 말 이 죠 . 그런데 심리 지수 란 건 뭘까요 ? 사람 들 이 특정 한 식 으로 행동 하 는 이유 에 대해 여러분 은 얼마나 알 고 계시 나요 ? 또 타인 이나 심지어 여러분 의 행동 을 예측 하 는 일 은 얼마나 잘 하 시 나요 ? 또 , 심리학 에 대해 갖춘 지식 중 에서 어느 정도 나 잘못 된 것 일까요 ? 심리학 에 관한 열 가지 신화 를 통해 잘못 된 것 들 을 알아보 도록 하 죠 . 여러분 은 한 번 쯤 들 어 보 셨 을 법 한 것 은 자신 들 의 심리학 에 대해 고려 할 때 , 거의 항상 남자 는 화성 에서 왔 고 , 여자 는 금성 에서 온 것 같 다고 합니다 . 하지만 실제로 남자 와 여자 는 얼마나 다른 걸까요 ? 이 를 알아보 기 위해 , 일단 남녀 사이 에 확실 하 게 차이 나 는 것 을 살펴보 고 심리학 적 인 성별 간 의 차이점 을 동일 한 척도 상 에서 대비 해 보 도록 하 겠 습니다 . 남자 와 여자 간 에 실제로 차이 나 는 능력 중 하나 는 그 들 이 공 을 얼마나 멀리 던질 수 있 느냐 하 는 것 입니다 . 여기 남자 들 의 데 이타 를 보 시 면 , 정상 분포 곡선 이 라는 걸 볼 수 있 습니다 . 남자 들 소수 는 정말 멀리 던지 고 , 남자 들 소수 는 멀리 던지 지 못하 지만 , 남자 들 대부분 은 평균 적 인 거리 를 던졌 습니다 . 여자 들 도 역시 비슷 한 분포 상태 를 보입니다 만 사실 남녀 사이 엔 커다란 차이 가 있 습니다 . 사실 , 평균 수준 의 남자 라면 모든 여성 중 대략 98 % 보다 더 멀리 던질 수 있 거든요 . 이 와 동일 하 게 표준 화 된 척도 상 에서 심리학 에서 말 하 는 성별 간 의 차이 를 살펴 봅시다 . 심리학자 라는 여러분 에게 말 하 길 남자 들 의 공간 지각 능력 이 여자 들 보다 뛰어나 다고 할 겁니다 . 예 를 들 어 , 지도 읽 는 능력 같 은 건데 , 맞 는 말 입니다 . 하지만 그 차이 의 정도 를 살펴봅시다 . 아주 작 죠 . 두 선 이 너무 근접 해서 거의 겹칠 정도 입니다 .\n","'''\n","\n","doc2 = '''\n","최상 의 제시 유형 은 학습 자 에 좌우 되 는 것 이 아니 라 학습 해야 할 내용 에 따라 좌우 됩니다 . 예 를 들 어 여러분 이 운전 하 기 를 배울 때 실제로 몸 으로 체감 하 는 경험 없이 누군가 가 어떻게 할 지 이야기 하 는 것 을 듣 는 것 만 으로 배울 수 있 습니까 ? 연립 방정식 을 풀 어야 하 는데 종이 에 쓰 지 않 고 머리 속 에서 말 하 는 것 으로 풀 수 가 있 을까요 ? 또는 만일 여러분 이 체감 형식 의 학습 자 유형 이 라면 , 건축학 시험 을 해석 적 춤 을 이용 하 여 수정 할 수 있 을까요 ? 아니 죠 ! 배워야 할 내용 을 제시 된 유형 에 맞추 어야 합니다 , 당신 에게 맞추 는 게 아니 라요 . 여러분 들 상당수 가 \" A \" 급 의 우등 생 이 라는 걸 아 는데 , 조만간 중등 학력 인증 시험 ( GCSE ) 결과 를 받 게 되 시 겠 네요 . 그런데 , 만일 , 여러분 들 이 희망 했 던 성적 을 받 지 못하 게 된다 해도 여러분 들 의 학습 방식 을 탓 해서 는 안 되 는 겁니다 . 여러분 이 비난 할 수 있 는 한 가지 는 바로 유전자 입니다 . 이건 최근 에 런던 대학교 ( UCL ) 에서 수행 했 던 연구 결과 는 여러 학생 들 과 그 들 의 중등 학력 인증 시험 결과 사이 의 차이 중 58 % 는 유전 적 인 요인 으로 좁혀졌 습니다 . 매우 정밀 한 수치 처럼 들립니다 . 그러면 어떻게 알 수 있 을까요 ? 유전 적 요인 과 환경 적 요인 의 상대 적 기여 도 를 알 고 싶 을 때 우리 가 사용 할 수 있 는 방식 은 바로 쌍둥이 연구 입니다 . 일 란 성 쌍생아 의 경우 환경 적 요인 과 유전 적 요인 모두 를 100 % 똑같이 공유 하 게 되 지만 이란 성 쌍생아 의 경우 는 100 % 동일 한 환경 을 공유 하 지만 유전자 의 경우 여타 의 형제자매 들 처럼 50 % 만 공유 하 게 됩니다 . 따라서 일 란 성 쌍둥이 와 이란 성 쌍둥이 사이 의 인증 시험 결과 가 얼마나 비슷 한지 비교 해 보 고 여기 에 약간 의 수학 적 계산 을 더하 게 되 면 그 수행 능력 의 차이 중 어느 정도 가 환경 적 요인 의 탓 이 고 어느 정도 가 유전자 탓 인지 를 알 수 있 게 됩니다 .\n","'''\n","\n","doc3 = '''\n","그러나 이 이야기 는 세 가지 이유 로 인해 신화 입니다 . 첫째 , 가장 중요 한 건 실험실 가운 은 흰색 이 아니 라 회색 이 었 다 라는 점 이 죠 . 둘째 , 참 여자 들 은 실험 하 기 전 에 와 참여 자 들 이 걱정 을 표현 할 때 마다 상기 시키 는 말 을 들 었 는데 , 전기 충격 이 고통 스럽 기 는 하 지만 , 치명 적 이 지 는 않 으며 실제로 영구 적 인 손상 을 남기 는 일 은 없 을 거 라는 것 이 었 습니다 . 셋째 , 참 여자 들 은 단지 가운 을 입 은 사람 이 시켜 전기 충격 을 주지 는 않 았 죠 . 실험 이 끝나 고 그 들 의 인터뷰 를 했 을 때 모든 참여 자 들 은 강한 신념 을 밝혔 는데 , ' 학습 과 처벌 ' 연구 가 과학 적 으로 가치 있 는 목적 을 수행 했 기 때문 에 비록 동료 참여 자 들 에게 가해진 순간 적 인 불편 함 에 반해서 과학 을 위해서 오래 남 을 성과 를 얻 을 것 이 라고 말 이 죠 . 그러 다 보 니 제 가 이야기 를 한 지 벌써 12 분 이 되 었 습니다 . 여러분 들 중 에 는 아마 거기 앉 아서 제 이야기 를 들으시는 동안 저 의 말투 와 몸짓 을 분석 하 면서 제 가 말 하 는 어떤 것 을 인지 해야 할까 해결 하 려고 하 셨 을 겁니다 , 제 가 진실 을 이야기 하 는 지 , 또는 거짓말 을 하 고 있 는 것 인지 말 이 죠 . 만일 그러 셨 다면 , 아마 지금 쯤 완전히 실패 하 셨 을 겁니다 . 왜냐하면 우리 모두 가 사람 이 말 하 는 패턴 과 몸짓 으로 도 거짓말 여부 를 알아내 는 것 이 가능 하 다고 생각 하 지만 , 오랜 세월 수백 회 에 걸쳐 행해진 실제 심리 검사 의 결과 를 보 면 우리 들 모두 는 , 심지어 경찰관 이나 탐정 들 을 포함 해서 도 기본 적 으로 몸짓 과 언어 적 패턴 으로 거짓말 을 탐지 하 는 것 은 운 에 맞 길 수 밖 에 는 없 는 것 입니다 . 흥미 롭 게 도 한 가지 예외 가 있 는데요 : 실종 된 친척 을 찾 아 달 라고 호소 하 는 TV 홍보 입니다 .\n","'''\n","\n","display (get_tfidf([doc1, doc2, doc3]).head(10))\n","display (get_tfidf([doc1, doc2, doc3]).tail(10))"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23</th>\n","      <td>남자</td>\n","      <td>9</td>\n","      <td>9.887511</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.887511</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>요인</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>6.591674</td>\n","      <td>0.000000</td>\n","      <td>6.591674</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>심리학</td>\n","      <td>5</td>\n","      <td>5.493061</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.493061</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>었</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>제</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>시험</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>멀리</td>\n","      <td>4</td>\n","      <td>4.394449</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>환경</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>성</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>인증</td>\n","      <td>3</td>\n","      <td>0.000000</td>\n","      <td>3.295837</td>\n","      <td>0.000000</td>\n","      <td>3.295837</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   word  frequency      doc1      doc2      doc3       max\n","23   남자          9  9.887511  0.000000  0.000000  9.887511\n","37   요인          6  0.000000  6.591674  0.000000  6.591674\n","51  심리학          5  5.493061  0.000000  0.000000  5.493061\n","57    었          4  0.000000  0.000000  4.394449  4.394449\n","63    제          4  0.000000  0.000000  4.394449  4.394449\n","70   시험          4  0.000000  4.394449  0.000000  4.394449\n","69   멀리          4  4.394449  0.000000  0.000000  4.394449\n","68   환경          4  0.000000  4.394449  0.000000  4.394449\n","64    성          4  0.000000  4.394449  0.000000  4.394449\n","98   인증          3  0.000000  3.295837  0.000000  3.295837"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>45</th>\n","      <td>된</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>그</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>지만</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>때</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>와</td>\n","      <td>6</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>라는</td>\n","      <td>6</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>중</td>\n","      <td>6</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>습니다</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>보</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>는</td>\n","      <td>47</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   word  frequency  doc1  doc2  doc3  max\n","45    된          5   0.0   0.0   0.0  0.0\n","44    그          5   0.0   0.0   0.0  0.0\n","42   지만          5   0.0   0.0   0.0  0.0\n","39    때          5   0.0   0.0   0.0  0.0\n","38    와          6   0.0   0.0   0.0  0.0\n","36   라는          6   0.0   0.0   0.0  0.0\n","33    중          6   0.0   0.0   0.0  0.0\n","30  습니다          7   0.0   0.0   0.0  0.0\n","29    보          7   0.0   0.0   0.0  0.0\n","0     는         47   0.0   0.0   0.0  0.0"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"5r8cWNIoguOv","colab_type":"text"},"source":["### TF Matrix\n","\n","문서별 단어 출현 횟수"]},{"cell_type":"code","metadata":{"id":"6qIQltQdguRu","colab_type":"code","colab":{}},"source":["def get_tf(docs) :\n","    vocab = {}\n","    tfs = []\n","    for d in docs : \n","        vocab = get_term_frequency(d, vocab)\n","        tfs += [get_term_frequency(d)]\n","\n","    from operator import itemgetter\n","    import numpy as np\n","\n","    stats= []\n","    for word, freq in vocab.items():\n","        tf_v = []\n","        for idx in range(len(docs)) :\n","            if tfs[idx].get(word) is not None :\n","                tf_v += [tfs[idx][word]]\n","            else : \n","                tf_v += [0]\n","        stats.append((word, freq, *tf_v))\n","    return pd.DataFrame(stats, columns=('word','frequency','doc1','doc2','doc3')).sort_values('frequency', ascending=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFUw4UiSguTY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"cedea550-3c2e-48a7-faad-682d36570c27","executionInfo":{"status":"ok","timestamp":1591062878229,"user_tz":-540,"elapsed":829,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["get_tf([doc1, doc2, doc3])"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>는</td>\n","      <td>47</td>\n","      <td>15</td>\n","      <td>14</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>을</td>\n","      <td>39</td>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>.</td>\n","      <td>36</td>\n","      <td>16</td>\n","      <td>10</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>하</td>\n","      <td>33</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>이</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>273</th>\n","      <td>스럽</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>274</th>\n","      <td>치명</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>275</th>\n","      <td>으며</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>영구</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>최근</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>437 rows × 5 columns</p>\n","</div>"],"text/plain":["    word  frequency  doc1  doc2  doc3\n","0      는         47    15    14    18\n","1      을         39     8    10    21\n","2      .         36    16    10    10\n","3      하         33    10     9    14\n","4      이         32     8     8    16\n","..   ...        ...   ...   ...   ...\n","273   스럽          1     0     0     1\n","274   치명          1     0     0     1\n","275   으며          1     0     0     1\n","276   영구          1     0     0     1\n","436   최근          1     0     1     0\n","\n","[437 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"iP13Enk-guVd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":81},"outputId":"26b5cfb3-422a-4fb6-9471-867f25840173","executionInfo":{"status":"ok","timestamp":1591062956977,"user_tz":-540,"elapsed":686,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["tf_df = get_tf([doc1, doc2, doc3])\n","tf_df[tf_df['word'] == '여러분']"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>여러분</td>\n","      <td>12</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   word  frequency  doc1  doc2  doc3\n","15  여러분         12     5     6     1"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"dWZJb6p3guXB","colab_type":"text"},"source":["#### Context Window\n","\n","- windowing ; 함께 나타나는 단어 조사, 동시발생 단어 활용\n","- t-SNE 를 통해 시각화 ; t-distributed stochastic neighbor embedding"]},{"cell_type":"code","metadata":{"id":"C6HuOwHhwDwR","colab_type":"code","colab":{}},"source":["from collections import defaultdict\n","import pandas as pd\n","\n","def get_context_counts(lines, w_size = 2) :\n","    co_dict = defaultdict(int)\n","\n","    for line in lines : \n","        words = line.split()\n","\n","        for i, w in enumerate(words) :\n","            for c in words[i - w_size : i + w_size ] :\n","                if w != c :\n","                    co_dict[(w, c)] += 1\n","\n","    return pd.Series(co_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLpTLz8IwD0q","colab_type":"code","colab":{}},"source":["def co_occurrence(co_dict, vocab) :\n","    data = []\n","    for word1 in vocab :\n","        row = []\n","        for word2 in vocab :\n","            try:\n","                count = co_dict[(word1, word2)]\n","            except KeyError : \n","                count = 0\n","            row.append(count)\n","        data.append(row)\n","    return pd.DataFrame(data, index = vocab, columns = vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFjU_G5QwEAQ","colab_type":"text"},"source":["## Vector Similarity"]},{"cell_type":"code","metadata":{"id":"UA5R8v4iwEDq","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YuIwuPNE03u_","colab_type":"text"},"source":["### L1 distance\n","\n","- Manhattan Distance"]},{"cell_type":"code","metadata":{"id":"mvS6ucmawEHH","colab_type":"code","colab":{}},"source":["def get_l1_distance(x1, x2) :\n","    return ((x1 - x2).abs()).sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TP__wVUZwEJW","colab_type":"text"},"source":["### L2 distance\n","\n","- Euclidean Distance"]},{"cell_type":"code","metadata":{"id":"1dNL4NfPwELd","colab_type":"code","colab":{}},"source":["def get_l2_distance (x1, x2) :\n","    return ((x1 - x2) ** 2).sum() ** 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frjyPImCwEN8","colab_type":"text"},"source":["### infinity Norm\n"]},{"cell_type":"code","metadata":{"id":"sae_y_JkwEP1","colab_type":"code","colab":{}},"source":["def get_infinity_distance(x1, x2) :\n","    return ((x1 - x2).abs()).max()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOVnmdb_wESR","colab_type":"text"},"source":["### Cosine Similarity\n","\n","- 가장 널리 쓰이는 유사도 측정 방법\n","- 다만 벡터 차원 크기 커질수록 연산량 크게 증가, 차원의 저주\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lT414s7MwEUk","colab_type":"code","colab":{}},"source":["def get_cosine_similarity (x1, x2) :\n","    return (x1 * x2).sum() / ((x1 ** 2).sum() ** .5 * (x2 ** 2).sum() ** .5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uS22t1PFguZN","colab_type":"text"},"source":["### Jaccard Similarity\n","\n","- 두 집합의 교집합 크기를 합집합 크기로 나누는 방식"]},{"cell_type":"code","metadata":{"id":"xRiPa_TjguNh","colab_type":"code","colab":{}},"source":["def get_jaccard_similarity (x1, x2) :\n","    return torch.stack([x1, x2]).min(dim = 0)[0].sum() / torch.stack([x1, x2]).max(dim = 0)[0].sum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"egduRhqB3BLQ","colab_type":"code","colab":{}},"source":["torch.stack?"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1E7XSVLT7p3Q","colab_type":"text"},"source":["위에서 만든 context windown를 dataframe으로 불러와서 각 유사도 측정방법으로 측정"]},{"cell_type":"code","metadata":{"id":"IcGV0KTP6fSp","colab_type":"code","colab":{}},"source":["def get_nearest(query:str, dataframe, metric, top_k, ascending=True)\n","    vector = torch.FloatTensor(dataframe.loc[query].values)\n","    distances = dataframe.apply(lambda x : metric(vector, torch.FloatTensor(x.values)), axis = 1)\n","    top_distances = distances.sort_values(ascending = ascending)[:top_k]\n","\n","    print (', '.join([f\"{k} ({v:.1f})\" for k, v in top_distances.items()]))\n","\n","query = '우리'\n","get_nearest(query, dataframe, get_l1_distance, 30 )\n","get_nearest(query, dataframe, get_l2_distance, 30 )\n","get_nearest(query, dataframe, get_infinity_distance, 30 )\n","get_nearest(query, dataframe, get_cosine_similarity, 30 )\n","get_nearest(query, dataframe, get_jaccard_similarity, 30 )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUoavXWp3D9n","colab_type":"text"},"source":["## 단어 중의성 해소\n","\n","### Lesk Algorithm\n","\n","- 가장 간단한 사전 기반 중의성 해소 방법\n","- 가정 : 문장 내 같이 등장하는 단어들은 공통 토픽을 공유\n"]},{"cell_type":"code","metadata":{"id":"vFWDStop47Aq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"39d8ddd3-3649-4061-bb86-c4bb4edca9b8","executionInfo":{"status":"ok","timestamp":1591065513830,"user_tz":-540,"elapsed":8548,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["from nltk.corpus import wordnet as wn\n","for ss in wn.synsets('bass') : print (ss, ss.definition())"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Synset('bass.n.01') the lowest part of the musical range\n","Synset('bass.n.02') the lowest part in polyphonic music\n","Synset('bass.n.03') an adult male singer with the lowest voice\n","Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n","Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n","Synset('bass.n.06') the lowest adult male singing voice\n","Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n","Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n","Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nZCXgHMU5GHz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f5c750e8-3b98-4335-97a1-1891f38535fd","executionInfo":{"status":"ok","timestamp":1591065813425,"user_tz":-540,"elapsed":568,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["def lesk(sentence, word) :\n","    from nltk.wsd import lesk\n","    best_synset = lesk( sentence.split(), word)\n","    print (best_synset, best_synset.definition())\n","\n","sentence = u'I went fishing last weekend and I got a bass and cooked it'\n","word = 'bass'\n","lesk(sentence, word)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJNGsIPX8QdE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e56649b9-d08e-4bff-8554-f0bd07de9e8f","executionInfo":{"status":"ok","timestamp":1591066300341,"user_tz":-540,"elapsed":592,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["sentence = 'I love the music from the speaker which has strong beat and bass'\n","word = 'bass'\n","lesk(sentence, word)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Synset('bass.n.02') the lowest part in polyphonic music\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"12_pMBqS8Upr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d92cce34-881c-49ca-a4ca-14056967d710","executionInfo":{"status":"ok","timestamp":1591066317431,"user_tz":-540,"elapsed":628,"user":{"displayName":"위정훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQk8IaD99RRrCRHxgn-DEiTezQkoQkqirklvFgV4=s64","userId":"11231217755361398606"}}},"source":["sentence = 'I think the bass is more important than guitar'\n","word = 'bass'\n","lesk(sentence, word)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WdWLpmHX8eB5","colab_type":"text"},"source":["## Selectional Preference\n","\n","- 문장 내 주변 단어들에 따라 의미 추정\n","- 단어-단어 관계가 좀더 특별한 경우를 수치화\n","- Selectional preference strength : KLD (쿨백-라이블러 발산) 활용, 술어 동사predicative verb 주어졌을 때 목적어 역할의 표제어headword 단어들의 분포\n","- selectional association : 특정 동사와 좀더 자주 출현하는 클래스의 목적어일수록 높게 나타남\n","- WordNet 기반 selectional preference 추정\n","- pseudo word 유사어휘를 통한 selectional preference 평가\n","- 유사도 기반 selectional preference ; WordNet 기반 추정의 경우 특정 언어에 국한, 신조어 반영 불가, thesaurus에 의존하지 않는 데이터 기반 선택 선호도 추정; corpus에 따라 유사도 추정 대상이 달라지는 coverage 문제\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"dE9KyLcR3MkO","colab_type":"code","colab":{}},"source":["!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwdAafA24wsL","colab_type":"code","colab":{}},"source":["!pip install konlpy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmFEa3kQ8hMU","colab_type":"code","colab":{}},"source":["from konlpy.tag import Mecab, Kkma"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ucFn2bi8hKq","colab_type":"code","colab":{}},"source":["def count_seen_headwords(lines, predicate = 'VV', headword = 'NNG') :\n","    tagger = Kkma()\n","    seen_dict = {}\n","\n","    for line in lines : \n","        pos_result = tagger.pos(line)\n","        word_h = None\n","        word_p = None\n","\n","        for word, pos in pos_result :\n","            if pos == predicate or pos[:3] == predicate + '+' :\n","                word_p = word\n","                break\n","            if pos == headword :\n","                word_h = word\n","        if word_h is not None and word_p is not None :\n","            seen_dict[word_p] = [word_h] + ([] if seen_dict.get(word_p) is None else seen_dict[word_p])\n","    \n","    return seen_dict\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wlgpn-b88hIJ","colab_type":"code","colab":{}},"source":["def get_selectional_association(predicate, headword, lines, dataframe, metric) :\n","    v1 = torch.FloatTensor(dataframe.loc[headword].values)\n","\n","    # seen_headwords : 위의 count_seen_headwords()로 return 한 값\n","    seens = seen_headwords[predicate]\n","\n","    total = 0\n","    for seen in seens :\n","        try :\n","            v2 = torch.FloatTensor(dataframe.loc[seen].values)\n","            total += metric(v1, v2)\n","        except :\n","            pass\n","    return total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hh8VeJD8hDp","colab_type":"code","colab":{}},"source":["def wsd (predicate, headwords) :\n","    selectional_associations = []\n","    for h in headwords :\n","        selectional_associations += [get_selectional_association(predicate, h, lines, co, get_cosine_similarity)]\n","    print (selectional_associations)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hway_VB38hBk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-l_JVky08g-4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7loFZHtG8gxb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9axL2fR8guY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}