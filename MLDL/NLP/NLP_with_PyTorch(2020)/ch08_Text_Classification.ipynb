{"cells":[{"cell_type":"markdown","metadata":{"id":"Ijkp4IrEdLrp","colab_type":"text"},"source":["# Ch08. Text Classification\n","\n","현업에서 가장 수요가 많은 문제\n","\n","## Naive-Baye's Classification\n","\n","딥러닝 이전 가장 간단한 분류 방식\n","\n","- 가장 간단하지만 기대 이상의 성능\n","- 단어를 불연속적 symbol로 다루는 것이 단점\n","\n","### MAP\n","\n","- Maximum a Posterior\n","\n","***Baye's theorem***\n","\n","posterior = likelihood * prior / evidence\n","\n","- posterior, 사후 확률\n","- likelihood, 가능도/우도\n","- prior, 사전 확률\n","- evidence, 증거\n","\n","> 대부분 문제에서 evidence 를 구하기 어려우므로, 사후확률을 최대화하는 prior를 구함\n","\n","cf) MLE, 최대가능도 추정 ; evidence가 나타날 가능도를 최대로 하는 클래스를 선택하는 것\n","\n","#### MLE vs MAP\n","\n","- MAP은 경우에 따라 MLE에 비해 더 정확 ; 사전 확률이 반영되어있기 때문\n","- 이미 갖고 있는 likelihood에 prior를 곱해주면 posterior를 최대화하는 클래스를 더 정확하게 예측 가능; 군부대에서 신발크기가 235일 때 신발 주인이 남성일 확률\n","\n","### Naive Baye's\n","\n","- MAP 기반 ; 텍스트 분류에서, n개의 단어가 주어졌을 때, 문장이 c클래스에 속할 확률값\n","- 보통 확률은 코퍼스 출현 빈도로 추정, 특징이 복잡할 수록 가능도 / 사후 확률 만족할 확률은 0에 가까워짐\n","- Naive Baye's는 각 특징을 독립적으로 가정, 각 특징의 결합 확률을 각 독립된 확률 곱으로 근사\n","- 각 특징들의 확률 곱에서 사전 확률 곱한 값을 최대화하는 클래스; 이때 사전 확률은 실제 corpus에서 출현한 빈도를 통해 추정\n","\n","### add-one Smoothing\n","\n","- 데이터 중 일부가 확률이 0 인경우, 전체 확률을 0으로 추정하는 문제\n","- 각 출현 횟수에 1을 더해주어 간단하게 해결; 완벽한 해결은 아님\n","\n","### Strong & Limit\n","\n","- 단순히 출현 빈도 세는 방식으로 분류\n","- 그러나 'not'과 같이 단어 하나 추가로 문장 뜻이 정반대가 되는 경우들 문제\n","- 각 단어의 출현 여부는 물론, 단어간 순서 문제도 중요\n","- label 당 문장 수가 매우 적은 경우에 한해 사용\n","\n","## Some Problems\n","\n","표제어 추출 lemmatization / 어간 추출 stemming 에 따라 접사 등 제거한 이후 텍스트 분류 적용할 경우 문제\n","\n","- 희소성 문제는 훨씬 더 줄일 수 있음; corpus 부족한 상황에서 어느정도 타협 볼 수 있으나..\n","- 딥러닝 이후 차원 축소 가능해지면서, 희소성 문제는 더 이상 장애물이 아님\n","- 접사에 따라 감성 분류 결과가 달라지는 경우도 상당수\n","- 따라서 표제어/어간 추출 하지 않은 상태에서, 신경망 모델 사용하여 분류 문제 해결 - 이후 성능 향상 차원에서 여러가지 튜닝, 시도할 때 corpus 양 부족이 성능 저하 원인이라는 가정이 성립되는 경우에 추가 실험\n","\n","## Using RNN\n","\n","### Architecture of RNN - Text Classification\n","\n","- input := (size of mini-batch) * (length of sentence) * (dimensions of one-hot-vectors)\n","  - one-hot-vector 다 가져갈 필요없이, 각 vector별 1의 위치 인덱스만 기억하여 2차원으로 차원 축소 - embedding\n","- ouput := sentence embedding vector - softmax\n","\n","### Pytorch Example\n","\n","- LSTM ; 내부 각 계층간에는 dropout 추가 됨\n","- NLL(음의 로그 가능도) 손실 함수로 최적화하기 위해 일반 softmax 대신 로그 확률 반환하는 logsoftmax 사용\n","- https://github.com/kh-kim/simple-ntc/blob/master/simple_ntc/models/rnn.py\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class RNNClassifier (nn.Module) :\n","    def __init__(self,\n","                 input_size,\n","                 word_vec_dim,\n","                 hidden_size,\n","                 n_classes,\n","                 n_layers = 4,\n","                 dropout_p = .3\n","                 ):\n","        \n","        self.input_size = input_size\n","        self.word_vec_dim = word_vec_dim\n","        self.hidden_size = hidden_size\n","        self.n_classes = n_classes\n","        self.n_layers = n_layers\n","        self.dropout_p = dropout_p\n","        \n","        super().__init__()\n","        \n","        self.emb = nn.Embedding(input_size, word_vec_dim)\n","        self.rnn = nn.LSTM(input_size= word_vec_dim,\n","                           hidden_size= hidden_size,\n","                           num_layers = n_layers,\n","                           dropout= dropout_p,\n","                           batch_first= True,\n","                           bidirectional= True\n","                           )\n","        self.generator = nn.Linear(hidden_size*2, n_classes)\n","        self.activation = nn.LogSoftmax(dim = -1)\n","    \n","    def forward(self, x):\n","        \n","        # |x| = (batch_size, length)\n","        x = self.emb(x)\n","        # |x| = (batch_size, length, word_vec_dim)\n","        x, _ = self.rnn(x)\n","        # |x| = (batch_size, length, hidden_size * 2)\n","        y = self.activation(self.generator(x[:, -1]))\n","        # |y| = (batch_size, n_classes)\n","        return y\n"]},{"cell_type":"markdown","metadata":{},"source":["## Using CNN\n","\n","- 2014년 발표된 논문 이후, NLP에서 RNN이 아닌 CNN도 사용하게 됨\n","- n*k 크기 sentence embedding matrix - convolution filter layers - max-pooling - dropout, FC layer, softmax - output\n","\n","### Convolution Filter\n","\n","- CNN 목적 자체가 기존 전통적인 영상 처리에서 사용되던 각종 convolution filter의 자동 구성을 위한 학습\n","- 윤곽선 edge 검출 - 객체 탐지 object detection\n","- convolution layer : convolution operation 을 통해 feedforward 값에 backpropagation을 수행해 개선된 convolution filter 값을 찾아나감\n","- 음성/오디오 신호에서도 Fourier Transform을 통해 2차원 시계열 데이터를 얻고, 패턴을 찾는 convolution operation이 매우 유용\n","\n","### Apply to Text Classification\n","\n","- one-hot-vector - word-embedding-vector (1d vector) - sum(word-embedding-vectors in sentence ; 2d vector) - convolution operation\n","- input := (number of senteces) * (number of time-steps in a sentence) * (vectors in time-step) * (number of filters) * (number of words)\n","- 논문에서는 영어의 경우, 3~5개 단어 조합에 대해 각각 100개씩 filter 가질 경우 성능 좋다는 결과\n","- filter별 score, CNN output을 MaxPooling - sentence embedding vector - softmax - output (classification)\n","\n","### PyTorch Example\n","\n","- https://github.com/kh-kim/simple-ntc/blob/master/simple_ntc/models/cnn.py"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class CNNClassifier(nn.Module) :\n","    def __init__(self,\n","                    input_size,\n","                    word_vec_dim,\n","                    n_classes,\n","                    use_batch_norm=False,\n","                    dropout_p = .5,\n","                    window_sizes = [3,4,5],\n","                    n_filters = [100,100,100]\n","                    ):\n","        self.input_size = input_size\n","        self.word_vec_dim = word_vec_dim\n","        self.n_classes = n_classes\n","        self.use_batch_norm = use_batch_norm\n","        self.dropout_p = dropout_p\n","        self.window_sizes = window_sizes\n","        self.n_filters = n_filters\n","        \n","        super().__init__()\n","        \n","        self.emb = nn.Embedding(input_size, word_vec_dim)\n","        self.feature_extractors = nn.ModuleList()\n","\n","        for window_size, n_filter in zip(window_sizes, n_filters) :\n","            self.feature_extractors.append(\n","                nn.Sequential(\n","                    nn.Conv2d(\n","                        in_channels=1,\n","                        out_channels=n_filter,\n","                        kernel_size=(window_size, word_vec_size),\n","                    ),\n","                    nn.ReLU(),\n","                    nn.BatchNorm2d(n_filter) if use_batch_norm else nn.Dropout(dropout_p),\n","                )\n","            )            \n","            # cnn = nn.Conv2d(in_channels=1,\n","            #                 out_channels=n_filter,\n","            #                 kernel_size=(window_size, word_vec_dim)\n","            #                 )\n","            # setattr(self, f'cnn-{window_size}-{n_filter}', cnn)\n","            # self.relu = nn.ReLU()\n","            # self.dropout = nn.Dropout(dropout_p)\n","            self.generator = nn.Linear(sum(n_filters), n_classes)\n","            self.activation = nn.LogSoftmax(dim=-1)\n","    \n","    def forward(self, x):\n","        \n","        x = self.emb(x)\n","        \n","        min_length = max(self.window_sizes)\n","        if min_length > x.size(1) :\n","            pad = x.new(x.size(0), min_length - x.size(1), self.word_vec_dim).zero_()\n","            x = torch.cat([x,pad], dim = 1)\n","        x = x.unsqueeze(1)\n","        \n","        cnn_outs = []\n","        # for window_size, n_filter in zip (self.window_sizes, self.n_filters) : \n","        #     cnn = getattr(self, f\"cnn-{window_size}-{n_filter}\")\n","        for block in self.feature_extractors:\n","            cnn_out = block(x)\n","            # cnn_out = self.dropout(self.relu(cnn(x)))\n","            cnn_out = nn.functional.max_pool1d(input = cnn_out.squeeze(-1),\n","                                                kernel_size = cnn_out.size(-2)).squeeze(-1)\n","            cnn_outs += [cnn_out]\n","        cnn_outs = torch.cat(cnn_outs, dim = -1)\n","        y = self.activation(self.generator(cnn_outs))\n","        return y"]},{"cell_type":"markdown","metadata":{},"source":["## Multi-label Classification\n","\n","### Using Multi-Binary Classification\n","\n","- BCELoss ; Binary Cross Entropy Loss\n","- 신경망 마지막 계층에 n개의 노드 모두 sigmoid 함수 적용\n","\n","### If not binary classification\n","\n","- multi softmax layers"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"},"orig_nbformat":2,"colab":{"name":"ch08_Text_Classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}