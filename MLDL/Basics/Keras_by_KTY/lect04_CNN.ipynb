{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lect04_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNsFYNHsYnhVC45ZbGUHE4m"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KeiNKL-qxbzl","colab_type":"text"},"source":["mkdate : 2020-05-03-SUN\n","\n","# 4강. CNN; Convolutional Neural Networks \n","\n","## 강의 :  딥러닝 입문에서 활용까지 케라스(Keras) \n","\n","##  제공처 : SKplanet Tacademy\n","\n","## Youtube\n","\n","-  [4강  Link](https://www.youtube.com/watch?v=f5X0An5KLR4&list=PL9mhQYIlKEheoq-M4EifTMPNWMw7poclK&index=4)\n","\n","## GithubPages\n","\n","-  [4강 Link](https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)\n","-  [4강  실습 Link](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)\n","\n","## 실습 dataset\n","\n","- [손글씨 이미지](http://tykimos.github.io/warehouse/2017-3-8_CNN_Getting_Started_handwriting_shape.zip)\n","\n","<br />\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"ijoY6a0Z8yF0","colab_type":"text"},"source":["# CNN; Convolutional Neural Networks\n","\n","## `keras.layers.convolutionalConv2D`\n","example)\n","```python\n","Conv2D(\n","            filters, \n","            kernel_size, \n","            strides=(1, 1), \n","            padding='valid', \n","            data_format=None, \n","            dilation_rate=(1, 1), \n","            activation=None, \n","            use_bias=True, \n","            kernel_initializer='glorot_uniform', \n","            bias_initializer='zeros', \n","            kernel_regularizer=None, \n","            bias_regularizer=None, \n","            activity_regularizer=None, \n","            kernel_constraint=None, \n","            bias_constraint=None, \n","            **kwargs)\n","\n","Conv2D(32, (5,5), padding = 'valid', input_shape=(28,28,1), activation='relu')\n","```\n","\n","### Argments\n","- `filers`\n","    - number of convolution filters\n","    - 출력 data  개수와 동일\n","\n","- `kernel_size` : (rows, cols) of convolutional kernels\n","\n","*학습 데이터 수 =  `filers` * `kernel rows` * `kernel cols`\n","\n","- `padding=` : 경계 처리 방법\n","![https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_4.png](https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_4.png)\n","\n","    -  `valid` : 유효한 영역만 출력,  따라서 출력 이미지 사이즈는 입력  이미지 사이즈보다 작다\n","    -  `same` : 출력 이미지 사이즈가 입력 이미지 사이즈와 동일\n","-  `input_shape=`: sample 수 제외한 입력 형태 정의. 첫 layer에서만 정의하면 됨\n","    -  `(rows, cols, channels)` : 흑백영상인 경우 channel == 1, RGB인 경우 channel=3\n","\n","### filter\n","\n","![https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_1.png](https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_1.png)\n","\n","- 하나의 filter로 전체 input에 대해 학습\n","- 지역적인 요소;  어떤 지역에 대해 학습한 내용이 다른 지역에 영향을 미치지 않음\n","-  Dense layer를 통해서도 구현할 수 있으나,  CNN을 사용하면  훨씬 적은 가중치를 통해서 더 좋은 성능을 만들 수 있음"]},{"cell_type":"markdown","metadata":{"id":"zhf28_cGIsKY","colab_type":"text"},"source":["## `keras.layers.convolutional.MaxPooling2D`\n","\n","```python\n","MaxPooling2D(\n","        pool_size=(2, 2), \n","        strides=None, \n","        padding='valid', \n","        data_format=None, \n","        **kwargs)\n","```\n","![https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_12.png](https://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_12.png)\n","\n","- 각 pixel에서 가장 큰 것만 추출해 이미지 size 축소,  사소한 변화는 무시 (추상화)\n","- 학습하는 내용은 없음\n","\n","###  Arguments\n","\n","- `pool_size=` : (rows, cols)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VBNV6yxQJKa4","colab_type":"text"},"source":["## `keras.layers.Flatten`\n","\n","```python\n","Flatten(\n","    data_format=None, \n","    **kwargs)\n","```\n","- 다차원 tensor를 1차원으로 flattening\n","- 학습하는 내용은 없음"]},{"cell_type":"markdown","metadata":{"id":"a8lB0tvZXdex","colab_type":"text"},"source":["## `ImageDataGenerator` : 데이터 부풀리기\n","\n","```python\n","ImageDataGenerator(\n","        featurewise_center=False, \n","        samplewise_center=False, \n","        featurewise_std_normalization=False, \n","        samplewise_std_normalization=False, \n","        zca_whitening=False, \n","        zca_epsilon=1e-06, \n","        rotation_range=0, \n","        width_shift_range=0.0, \n","        height_shift_range=0.0, \n","        brightness_range=None, \n","        shear_range=0.0, \n","        zoom_range=0.0, \n","        channel_shift_range=0.0, \n","        fill_mode='nearest', \n","        cval=0.0, \n","        horizontal_flip=False, \n","        vertical_flip=False, \n","        rescale=None, \n","        preprocessing_function=None, \n","        data_format='channels_last', \n","        validation_split=0.0, \n","        interpolation_order=1, \n","        dtype='float32')\n","```"]},{"cell_type":"markdown","metadata":{"id":"3J0AQG4WUpxk","colab_type":"text"},"source":["## 실습 :  원/삼각형/사각형 categorical classification\n","\n"]},{"cell_type":"code","metadata":{"id":"c3P7MzuhIht1","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVPVnGweTD1X","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4STUw96TXyTJ","colab_type":"code","colab":{}},"source":["ImageDataGenerator()"],"execution_count":0,"outputs":[]}]}